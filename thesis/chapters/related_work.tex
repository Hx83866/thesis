The prediction of the future course of a process instance has been an important subfield in process mining research, aiming to enhance process monitoring capabilities.
Depending on the use case, for example, predicting time-related attributes, the next activity or the outcome of a case can be of interest.
Most approaches presented in the literature either use process models or machine learning methods to construct a predictor, which generalizes from a historical event log.

Five different non-parametric regression predictors for forecasting the total cycle time of an unfinished case have been presented by \Citeauthor{DBLP:conf/otm/DongenCA08} \cite{DBLP:conf/otm/DongenCA08}.
The estimates are based on activity occurrences, activity duration, and other attributes.

Furthermore, \Citeauthor{DBLP:journals/is/AalstSS11} proposed building a transition system using a set, bag, or sequence abstraction, which is annotated with time-related data to predict the cycle time of case \cite{DBLP:journals/is/AalstSS11}.
The core idea of this approach is to replay unfinished cases on the learned transition system and compute the prediction using the historical measurements in the annotations.

\citeauthor{DBLP:conf/colcom/PandeyNC11} use a hidden Markov model to predict the cycle time of a case using the activity and timestamp data of an event log \cite{DBLP:conf/colcom/PandeyNC11}.

\citeauthor{DBLP:conf/icsoc/Rogge-SoltiW13} showed how a stochastic Petri net could be used to predict the cycle time of a process instance \cite{DBLP:conf/icsoc/Rogge-SoltiW13}.
The model naturally supports parallelism in business processes and considers future events, which are expected to occur. 

\citeauthor{DBLP:conf/dis/CeciLFCM14} presented an approach where a sequence tree is learned to relate running traces to similar historical traces \cite{DBLP:conf/dis/CeciLFCM14}.
A decision tree is then used to predict the next activity and the cycle time of a case.

\citeauthor{DBLP:conf/bpm/TeinemaaDMF16} applied text vectorization techniques like Bag of N-Gram (BoNG), Latent Dirichlet Allocation (LDA) and Paragraph Vectors (PV) to textual data of processes in order to predict a binary label describing the process outcome \cite{DBLP:conf/bpm/TeinemaaDMF16}.
In this approach, random forest and logistic regression classifiers for each prefix length of a trace are trained.

Most recently, several authors have applied recurrent neural networks in the form of LSTM networks for process prediction. \citeauthor{ DBLP:conf/bpm/EvermannRF16} encode events using an embedding matrix as it is known for word embeddings.
The embedded events are then used as input for an LSTM network that predicts the next activity \cite{DBLP:conf/bpm/EvermannRF16}.

\citeauthor{DBLP:conf/caise/TaxVRD17} use a one-hot encoding of the activity and the timestamp of an event to predict the activity and timestamp of the next event \cite{DBLP:conf/caise/TaxVRD17}.
This is done by using a two-layered LSTM network architecture.

The work by \citeauthor{DBLP:conf/ssci/NavarinVPS17} adopted the idea of using an LSTM network \cite{DBLP:conf/caise/TaxVRD17} and extends the encoding by also utilizing additional data attributes associated with each event \cite{DBLP:conf/ssci/NavarinVPS17} to predict the cycle time of a case.

\citeauthor{DBLP:journals/computing/PolatoSBL18} presented a set of approaches that use support vector regression for cycle time prediction  \cite{DBLP:journals/computing/PolatoSBL18}.
The authors implement different encodings for events in this contribution including a simple one-hot encoding and a more advanced state-based encoding using transition systems.
Furthermore, they enhance the approach in \cite{DBLP:journals/is/AalstSS11} by taking additional data attributes into account.

\citeauthor{DBLP:journals/tkdd/TeinemaaDRM19} reported an in-depth review and benchmark of outcome-oriented predictive process monitoring approaches.
The study showed that aggregated encodings like counting frequencies of activities are the most reliable encoding for predicting the outcome of a case \cite{DBLP:journals/tkdd/TeinemaaDRM19}.

\citeauthor{DBLP:conf/icpm/ParkS19} showed how LSTM-based predictions could be used to solve a resource allocation problem, leading to direct recommendations for process improvement \cite{DBLP:conf/icpm/ParkS19}.

The most extensive benchmarking of sequential prediction models has been realized by \citeauthor{DBLP:journals/sosym/TaxTZ20} \cite{DBLP:journals/sosym/TaxTZ20}.
The authors show that black-box process prediction methods from the machine learning field outperform process model-oriented techniques.
However, the latter are more efficient and offer higher interpretability at the cost of prediction quality.

A comparison of the process prediction methods is presented in Table \ref{tab:preliminaries}.
The table shows the underlying model that is used to generalize from historical event data for each approach.
The table also shows whether the methods use additional textual or non-textual data, and which prediction targets are supported.

\begin{table}[]
	\renewcommand{\arraystretch}{1.5}
	\begin{tabularx}{\textwidth}{
			>{\hsize=2.0\hsize}X
			>{\hsize=0.4\hsize}X
			>{\hsize=1.3\hsize}X
			>{\hsize=0.5\hsize}X
			>{\hsize=0.5\hsize}X
			>{\hsize=1.3\hsize}X
		}
		\toprule
		\textbf{Contribution} & \textbf{Year} & \textbf{Model(s)}  & \textbf{Data-Aware} &  \textbf{Text-Aware} & \textbf{Predictions} \\ \midrule
		 Van Dongen et al. \cite{DBLP:conf/otm/DongenCA08}& \citeyear{DBLP:conf/otm/DongenCA08} & Regression  & \checkmark & \xmark& Cycle time\\
		 
		 Van der Aalst et al. \cite{DBLP:journals/is/AalstSS11}&  \citeyear{DBLP:journals/is/AalstSS11}& Transition system  
		   & \xmark & \xmark & Cycle time \\   
		   
		 \citeauthor{DBLP:conf/colcom/PandeyNC11} \cite{DBLP:conf/colcom/PandeyNC11} & \citeyear{DBLP:conf/colcom/PandeyNC11} & Hidden Markov & \xmark & \xmark & Cycle time \\
		 
		 \citeauthor{DBLP:conf/icsoc/Rogge-SoltiW13} \cite{DBLP:conf/icsoc/Rogge-SoltiW13} & \citeyear{DBLP:conf/icsoc/Rogge-SoltiW13} &Stochastic Petri net & \xmark & \xmark & Cycle time\\
		 
		 \citeauthor{DBLP:conf/dis/CeciLFCM14} \cite{DBLP:conf/dis/CeciLFCM14} & \citeyear{DBLP:conf/dis/CeciLFCM14} & Sequence tree \newline Decision tree& \checkmark & \xmark & Next activity \newline Cycle time \\
		 
		 \citeauthor{DBLP:conf/bpm/TeinemaaDMF16}  \cite{DBLP:conf/bpm/TeinemaaDMF16} &  \citeyear{DBLP:conf/bpm/TeinemaaDMF16} & Random forest \newline Logistic regression & \checkmark & \checkmark & Case outcome \\
		 
		 \citeauthor{ DBLP:conf/bpm/EvermannRF16} \cite{ DBLP:conf/bpm/EvermannRF16} &  \citeyear{ DBLP:conf/bpm/EvermannRF16}& LSTM & \xmark & \xmark & Next activity \\
		 
		 \citeauthor{DBLP:conf/caise/TaxVRD17} \cite{DBLP:conf/caise/TaxVRD17} & \citeyear{DBLP:conf/caise/TaxVRD17} & LSTM & \xmark & \xmark & Next activity \newline Next event time \newline Cycle time \newline Future path \\
		 \citeauthor{DBLP:conf/ssci/NavarinVPS17} \cite{DBLP:conf/ssci/NavarinVPS17} &  \citeyear{DBLP:conf/ssci/NavarinVPS17}&  LSTM & \checkmark  & \xmark & Cycle time\\
		 
		 \citeauthor{DBLP:journals/computing/PolatoSBL18} \cite{DBLP:journals/computing/PolatoSBL18}&  \citeyear{DBLP:journals/computing/PolatoSBL18} &  Transition system \newline SVR \newline Naive Bayes &  \checkmark & \xmark & Next activity \newline Cycle time \newline Future path \\
		 
		 \citeauthor{DBLP:conf/icpm/ParkS19} \cite{DBLP:conf/icpm/ParkS19} & \citeyear{DBLP:conf/icpm/ParkS19} & LSTM & \checkmark & \xmark &Next activity \newline Next event time  \\
		 
		 This contribution &  2020 &  LSTM & \checkmark & \checkmark &  Next activity \newline Next event time  \newline Cycle time \newline Case outcome
	 	\\ \bottomrule
	\end{tabularx}
	\caption[Comparison  of process prediction methods]{Comparison  of process prediction methods.}
	\label{tab:preliminaries}
\end{table}