In this chapter, the performance of the text-aware process prediction model is evaluated based on real-life event data.
First, the data sets and evaluation method are described. Then, the performance of differently parameterized models on the data sets is evaluated and analyzed in-depth.


\section{Data Sets}

The prediction model is evaluated on two real-life event logs, which are described in the following. An overview of the key properties of the logs is summarized in Table \ref{tab:logs}.

\textbf{werk.nl} This event log describes customer's journeys of the Employee Insurance Agency commissioned by the Dutch Ministry of Social Affairs and Employment. The log is aggregated from two anonymized data sets, that were provided in the BPI Challenge 2016 \cite{bpichallenge2016}, containing click data of logged in customers from the official website werk.nl and phone call data from the call center.
Both data sets are joined based on the customer ID to derived a detailed view on customer contacts.
For each phone call the costumer's question is available as a text attribute in English. In addition, the customer's age (grouped) and gender is considered as additional attributes.
The event log is filtered to remove outlier activities (threshold <0.5\%) and infrequent trace variants (2 or less traces with the same variant). After prepossessing, 18 distinct activities and 1001 trace variants remain.

\textbf{Helpdesk}

\begin{table}[!htbp]
	\begin{tabularx}{\textwidth}{l r l }
		\toprule
		\textbf{Data Set} & \textbf{werk.nl} & \textbf{Helpdesk}  \\
		\midrule
		Number of cases & 15\,001& \\
		Number of trace variants & 1\,001 & \\
		Number of events & 55\,220 & \\
		Events per trace (avg.) & 3.681& \\
		Median case duration (days) & 0.225& \\
		Mean case duration (days)& 0.713 & \\
		Number of activities & 18 & \\
		Number of words (pre filtering) &247\,010 & \\
		Number of words (post filtering) &98\,915 & \\
		Vocabulary size (pre filtering) & 1\,203 & \\
		Vocabulary size (post filtering) & 815 & \\
		\bottomrule
	\end{tabularx}
	\caption[Overview of evaluated data sets]{Overview of evaluated data sets.}
	\label{tab:logs}
\end{table}

\section{Evaluation Method}

Each event log is evaluated in a consistent procedure.
In the first step, the event log is separated into a training and test log. 
The training log consists of the first 2/3 chronologically ordered traces and is used to fit the prediction model to the historical data.
The remaining 1/3 of traces are used to measure the prediction performance.
For each trace $\sigma$ in the test log, all prefixes $hd^k(\sigma)$ of length $2 \leq k \leq |\sigma| - 1$ are considered as instances for prediction.
For prefix traces with only one event, predictions seem to be less stable as also observed in \cite{DBLP:conf/caise/TaxVRD17} and are therefore not included for the metric computation.
The LSTM network is trained with at most 100 epochs and the learning rate is initialized with 0.001.
During the training of the LSTM model, 20\% of the training log is used for validation i.e. the training rate is reduced, if the error on the validation log is not decreasing anymore for 5 epochs, and the training is stopped, if the error is not decreased for 10 epochs in order to avoid overfitting.
Furthermore, the LSTM layers use dropout \cite{DBLP:journals/corr/abs-1207-0580} of 20\% during training as an additional measure against overfitting.

For classification (i.e. categorical prediction) task, like next event and outcome prediction, the accuracy is utilized as metric.
The accuracy is computed as the number of correct predictions $t$ divided by the total number of predictions $n$, i.e. 
\begin{equation*}
	\textrm{accuracy} = \dfrac{t}{n} = \dfrac{\textrm{\# correct predictions}}{\textrm{\# total predictions}}.
\end{equation*}

For regression tasks, like the next event time and the case cycle time predictions, the mean absolute error (MAE) is computed to measure the prediction performance. The mean absolute error indicates the average absolute difference between the predicted value $\hat{y}$ and the true value $y$,  i.e.
\begin{equation*}
	\textrm{MAE} = \dfrac{1}{n}\sum_{i=1}^{n}|\hat{y_i} - y_i|.
\end{equation*}
This error metric is favored, since it gives a more intuitive interpretation and is less sensitive to outliers compared to similar metrics like the mean squared error (MSE).


\section{Next Event Prediction}

\begin{table}[!htbp]
	\setlength\tabcolsep{3pt}
	\begin{tabularx}{\textwidth}{l l l l l l l l l }
		\toprule
		 &  &  &  &  & \multicolumn{2}{c}{werk.nl} & \multicolumn{2}{c}{Helpdesk}  \\
		Layers & Shared & Neurons & Text Model & Event Dim.&Accuracy & MAE (days) & Accuracy& MAE \\
		\midrule
		& & & & &&& & \\
		\bottomrule
	\end{tabularx}
	\caption[Experimental results for the next event prediction]{Experimental results for the next event prediction.}
	\label{tab:next-event}
\end{table}



\pgfplotscreateplotcyclelist{colorlist}{%
	cyan!60!black,every mark/.append style={fill=cyan!60!black},mark=*\\%1
	orange!60!black,every mark/.append style={fill=orange!60!black},mark=square*\\%2
	darkgray!60!black,every mark/.append style={fill=darkgray!60!black},mark=otimes*\\%3
	red!60!black,every mark/.append style={fill=red!60!black},mark=triangle*\\%4
	olive!60!black,every mark/.append style={fill=olive!60!black},mark=diamond*\\%5
}

\begin{figure}
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\begin{tikzpicture}[scale=0.9]
			\begin{axis}[
				title=Next Activity Prediction,
				xlabel={Prefix length},
				ylabel={},
				]
			\end{axis}
		\end{tikzpicture}
		\caption{A subfigure}
		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\begin{tikzpicture}[scale=0.9]
			\begin{axis}[
				title=Next Event Time Prediction,
				xlabel={Prefix length},
				ylabel={$y$},
				legend pos=north west,
				cycle list name=colorlist,
				]
				\addplot table[x=x,y=a, col sep= comma] {data/example.csv};
				\addlegendentry{$a$}
				\addplot table[x=x,y=b, col sep= comma] {data/example.csv};
				\addlegendentry{$b$}
				\addplot table[x=x,y=c, col sep= comma] {data/example.csv};
				\addlegendentry{$c$}
				\addplot table[x=x,y=d, col sep= comma] {data/example.csv};
				\addlegendentry{$d$}
				\addplot table[x=x,y=e, col sep= comma] {data/example.csv};
				\addlegendentry{$e$}
			\end{axis}
		\end{tikzpicture}
		\caption{A subfigure}
		\label{fig:sub2}
	\end{subfigure}
	\caption[Next activity prediction] {Next activity prediction.}
	\label{fig:test}
\end{figure}



\section{Outcome and Case Cycle Time Prediction}

\begin{table}[!htbp]
	\begin{tabularx}{\textwidth}{l l l l }
		\toprule
		& & &  \\
		\midrule
		& & & \\
		\bottomrule
	\end{tabularx}
	\caption[Experimental results for the case cycle time prediction]{Experimental results for the case cycle time prediction.}
	\label{tab:outcome-cycle-time}
\end{table}


